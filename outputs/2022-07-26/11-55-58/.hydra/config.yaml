optim_steps_per_batch: 64
optimizer: adam
lr_scheduler: ''
selected_keys: null
batch_size: 256
log_interval: 10000
lr: 0.0003
weight_decay: 0.0
clip_norm: 1000.0
clip_grad_norm: false
normalize_rewards_online: true
normalize_rewards_online_scale: 5.0
sub_traj_len: -1
collector_devices:
- cuda:1
- cuda:1
- cuda:1
- cuda:1
pin_memory: false
init_with_lag: false
frames_per_batch: 1024
total_frames: 1000000
num_workers: 4
env_per_collector: 1
seed: 42
exploration_mode: ''
async_collection: true
multi_step: true
n_steps_return: 3
init_random_frames: 25000
env_library: dm_control
env_name: cheetah
env_task: ''
from_pixels: false
frame_skip: 1
reward_scaling: null
reward_loc: 0.0
init_env_steps: 5000
vecnorm: false
norm_rewards: false
norm_stats: true
noops: 0
catframes: 0
center_crop: []
grayscale: true
max_frames_per_traj: -1
batch_transform: true
loss: double
hard_update: false
loss_function: smooth_l1
value_network_update_interval: 200
gamma: 0.99
num_q_values: 2
target_entropy: null
annealing_frames: 1000000
noisy: false
ou_exploration: true
ou_sigma: 0.2
ou_theta: 0.15
distributional: false
atoms: 51
gSDE: false
tanh_loc: false
default_policy_scale: 1.0
distribution: tanh_normal
actor_cells: 256
qvalue_cells: 256
scale_lb: 0.1
value_cells: 256
activation: elu
record_video: false
no_video: true
exp_name: ''
record_interval: 10
record_frames: 10000
recorder_log_keys:
- reward
buffer_size: 1000000
prb: true
buffer_scratch_dir: null
buffer_prefetch: 64
