collector_devices:
- cpu
pin_memory: false
init_with_lag: false
frames_per_batch: 1000
total_frames: 5000000
num_workers: 4
env_per_collector: 4
seed: 42
exploration_mode: ''
async_collection: true
multi_step: false
n_steps_return: 3
init_random_frames: 50000
env_library: dm_control
env_name: cheetah
env_task: run
from_pixels: true
frame_skip: 2
reward_scaling: null
reward_loc: 0.0
init_env_steps: 25000
vecnorm: false
norm_rewards: false
norm_stats: true
noops: 0
catframes: 0
center_crop: []
grayscale: true
max_frames_per_traj: -1
batch_transform: true
record_video: false
no_video: true
exp_name: ''
record_interval: 100
record_frames: 50000
recorder_log_keys:
- reward
buffer_size: 1000000
prb: false
buffer_scratch_dir: null
buffer_prefetch: 10
state_dim: 20
rssm_hidden_dim: 200
grad_clip: 100
world_model_lr: 0.0006
actor_value_lr: 8.0e-05
optim_steps_per_batch: 100
batch_size: 50
log_interval: 10000
